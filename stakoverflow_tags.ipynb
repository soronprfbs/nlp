{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Предсказание тегов с помощью линейных моделей\n",
    "\n",
    "Попробуем предсказывать теги к постам с сайта [StackOverflow](https://stackoverflow.com)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Предварительная обработка текста\n",
    "\n",
    "Для работы с текстом нам понадобится лист стоп-слов. Импортируем необходимые библиотеки."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В этой задаче предстоит иметь дело с набором данных заголовков постов из StackOverflow. Предоставлено разбиение на 3 датасета: *train*, *validation* и *test*. Все корпусы кроме *test* содержат названия постов и соответствующие теги (доступно 100 тегов). Корпус *test* не содержит ответов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ast import literal_eval\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Функция `literal_eval` из библиотеки `ast` позволяет поменять тип данных `str` на другой подходящий. Выглядит это так:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['a', 'b', 'c']\n",
      "<class 'str'>\n"
     ]
    }
   ],
   "source": [
    "# Создадим лист, но запишем его как строку\n",
    "string = \"['a', 'b', 'c']\"\n",
    "print(string)\n",
    "print(type(string))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['a', 'b', 'c']\n",
      "<class 'list'>\n"
     ]
    }
   ],
   "source": [
    "# Преобразуем строку в лист\n",
    "str_to_list = literal_eval(string)\n",
    "print(str_to_list)\n",
    "print(type(str_to_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`literal_eval` сама определяет тип данных и может работать со словарями:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'>\n",
      "<class 'dict'>\n"
     ]
    }
   ],
   "source": [
    "new_string = \"{'a': 1, 'b': 2, 'c': 3}\"\n",
    "print(type(new_string))\n",
    "str_to_dict = literal_eval(new_string)\n",
    "print(type(str_to_dict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь создадим функцию для чтения данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(filename):\n",
    "    data = pd.read_csv(filename, sep='\\t') # Разделителем выступает символ табуляции\n",
    "    data['tags'] = data['tags'].apply(literal_eval) # Применим literal_eval для нашей зависимой переменной\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = read_data('train.tsv')\n",
    "validation = read_data('validation.tsv')\n",
    "test = pd.read_csv('test.tsv', sep='\\t')\n",
    "# Заметьте, что в test мы используем функцию read_csv из библиотеки pandas, поэтому нам нужно указать разделитель\n",
    "# Созданную нами функцию read_data мы не можем применить, потому что test не содержит зависимую переменную"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Взглянем на данные"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>How to draw a stacked dotplot in R?</td>\n",
       "      <td>[r]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>mysql select all records where a datetime fiel...</td>\n",
       "      <td>[php, mysql]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>How to terminate windows phone 8.1 app</td>\n",
       "      <td>[c#]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>get current time in a specific country via jquery</td>\n",
       "      <td>[javascript, jquery]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>Configuring Tomcat to Use SSL</td>\n",
       "      <td>[java]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title                  tags\n",
       "0                How to draw a stacked dotplot in R?                   [r]\n",
       "1  mysql select all records where a datetime fiel...          [php, mysql]\n",
       "2             How to terminate windows phone 8.1 app                  [c#]\n",
       "3  get current time in a specific country via jquery  [javascript, jquery]\n",
       "4                      Configuring Tomcat to Use SSL                [java]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Why odbc_exec always fail?</td>\n",
       "      <td>[php, sql]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Access a base classes variable from within a c...</td>\n",
       "      <td>[javascript]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Content-Type \"application/json\" not required i...</td>\n",
       "      <td>[ruby-on-rails, ruby]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>Sessions in Sinatra: Used to Pass Variable</td>\n",
       "      <td>[ruby, session]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>Getting error - type \"json\" does not exist - i...</td>\n",
       "      <td>[ruby-on-rails, ruby, json]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0                         Why odbc_exec always fail?   \n",
       "1  Access a base classes variable from within a c...   \n",
       "2  Content-Type \"application/json\" not required i...   \n",
       "3         Sessions in Sinatra: Used to Pass Variable   \n",
       "4  Getting error - type \"json\" does not exist - i...   \n",
       "\n",
       "                          tags  \n",
       "0                   [php, sql]  \n",
       "1                 [javascript]  \n",
       "2        [ruby-on-rails, ruby]  \n",
       "3              [ruby, session]  \n",
       "4  [ruby-on-rails, ruby, json]  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Warning: mysql_query() expects parameter 2 to ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>get click coordinates from &lt;input type='image'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>How to implement cloud storage for media asset...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>What is catcomplete in jQuery's autocomplete p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>Error building Android app with Cordova 3.1 CLI</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title\n",
       "0  Warning: mysql_query() expects parameter 2 to ...\n",
       "1  get click coordinates from <input type='image'...\n",
       "2  How to implement cloud storage for media asset...\n",
       "3  What is catcomplete in jQuery's autocomplete p...\n",
       "4    Error building Android app with Cordova 3.1 CLI"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Столбец `title` содержит заголовки, а столбец `tags` теги (удивительно). Важно то, что столбец `tags` не имеет фиксированного количества тегов.\n",
    "\n",
    "Для удобства преобразуем наши данные в формат `np.array`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = train['title'].values, train['tags'].values\n",
    "X_val, y_val = validation['title'].values, validation['tags'].values\n",
    "X_test = test['title'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Выглядят они теперь вот так:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['How to draw a stacked dotplot in R?',\n",
       "       'mysql select all records where a datetime field is less than a specified value',\n",
       "       'How to terminate windows phone 8.1 app',\n",
       "       'get current time in a specific country via jquery',\n",
       "       'Configuring Tomcat to Use SSL'], dtype=object)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([list(['r']), list(['php', 'mysql']), list(['c#']),\n",
       "       list(['javascript', 'jquery']), list(['java'])], dtype=object)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Одна из распространённых проблем при работе с естественными данными заключается в том, что они неструктурированы. Например, если бы мы использовали данные *как есть* и извлекали из них токены, просто разделяя их пробелами, мы бы увидели, что существует много \"странных\" токенов, таких как *3.5*,  *flip* и т.д. Чтобы предотвратить это, необходимо как-то подготовить данные. Здесь мы напишем функцию для решения этой проблемы."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "REPLACE_BY_SPACE_RE = re.compile('[/(){}\\[\\]\\|@,;]') # Сохраняем паттерн, который будем использовать позже\n",
    "BAD_SYMBOLS_RE = re.compile('[^0-9a-z #+_]') # Ещё один паттерн\n",
    "STOPWORDS = set(stopwords.words('english')) # Сохраняем  подмножество стоп-слов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1, 2, 3, 4, 6, 7}\n"
     ]
    }
   ],
   "source": [
    "# Как работает set? Он возвращает множество уникальных элементов\n",
    "list_ = [7, 1, 2, 1, 2, 2, 3, 4, 6]\n",
    "print(set(list_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_prepare(text):\n",
    "    \"\"\"\n",
    "        text: a string\n",
    "        \n",
    "        return: modified initial string\n",
    "    \"\"\"\n",
    "    text = text.lower() # Меняем регистр всех символом на нижний\n",
    "    text = re.sub(REPLACE_BY_SPACE_RE, ' ', text) # Меняем символы из REPLACE_BY_SPACE_RE на пробел в объекте text\n",
    "    text = re.sub(BAD_SYMBOLS_RE, '', text) # Удаляем символы из BAD_SYMBOLS_RE (заменяем на ничего, не на пробел)\n",
    "    text = text.split(' ') # Разделяем текст там, где пробелы\n",
    "    text = [w for w in text if not w in STOPWORDS] # Создаём лист из слов текста, которых нет в STOPWRODS\n",
    "    text = [w for w in text if not w == ''] # Создаём лист из слов, которые не \"пустота\"\n",
    "    text = ' '.join(text) # Склеиваем лист с помощью пробела в одну строку\n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проверим работу нашей функции"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_text_prepare():\n",
    "    examples = [\"SQL Server - any equivalent of Excel's CHOOSE function?\",\n",
    "                \"How to free c++ memory vector<int> * arr?\"]\n",
    "    answers = [\"sql server equivalent excels choose function\", \n",
    "               \"free c++ memory vectorint arr\"]\n",
    "    for ex, ans in zip(examples, answers):\n",
    "        if text_prepare(ex) != ans:\n",
    "            return \"Wrong answer for the case: '%s'\" % ex\n",
    "    return 'Basic tests are passed.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Basic tests are passed.\n"
     ]
    }
   ],
   "source": [
    "print(test_text_prepare())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь, когда мы убедились, что наша функция работает, применим её к нашим данным (это необходимо сделать только для признаков, но не для тегов)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = [text_prepare(x) for x in X_train]\n",
    "X_val = [text_prepare(x) for x in X_val]\n",
    "X_test = [text_prepare(x) for x in X_test]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Выглядят они примерно так:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['draw stacked dotplot r',\n",
       " 'mysql select records datetime field less specified value',\n",
       " 'terminate windows phone 81 app',\n",
       " 'get current time specific country via jquery',\n",
       " 'configuring tomcat use ssl']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для каждого тега (отклика, ответа) и слова (данные с признаками) посчитаем, как часто они встречаются в *train* корпусе."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Создаём 2 пустых словаря для подсчёта тегов и слов\n",
    "tags_counts = {}\n",
    "words_counts = {}\n",
    "\n",
    "for line in y_train: # Проходимся по каждому листу\n",
    "    for word in line: # Проходимся по каждому слову в листе\n",
    "        tags_counts.setdefault(word, 0) # Выставляем значение 0 для каждого слова, если оно не встретилось раньше\n",
    "        # Если встретилось, предыдущая строчка пропускается\n",
    "        tags_counts[word] += 1 # Считаем встречаемость\n",
    "\n",
    "for line in X_train: # Тоже самое для признаков\n",
    "    for word in line.split(): # Но здесь строчку надо поделить, по умолчанию стоит пробел\n",
    "        words_counts.setdefault(word, 0)\n",
    "        words_counts[word] += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь мы можем найти самые встречаемые слова, просто отсортировав словари по значению."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('javascript', 19078), ('c#', 19077), ('java', 18661)] \n",
      " [('using', 8278), ('php', 5614), ('java', 5501)]\n"
     ]
    }
   ],
   "source": [
    "most_common_tags = sorted(tags_counts.items(), key=lambda x: x[1], reverse=True)[:3]\n",
    "# key здесь говорит о том, что мы берём 1-й элемент в словаре, то есть значение, а не ключ\n",
    "most_common_words = sorted(words_counts.items(), key=lambda x: x[1], reverse=True)[:3]\n",
    "print(most_common_tags, '\\n', most_common_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Трансформация текста в вектор\n",
    "\n",
    "Как мы знаем, алгоритмы машинного обучения могут работать только с числовыми данынми, поэтому мы не можем просто так использовать текст для обучения модели. Существует много методов преобразовать текст в числа, здесь мы познакомимся с двумя из них.\n",
    "\n",
    "#### Bag of words\n",
    "\n",
    "Один из самых популярных методов — метод мешка слов (bag of words). Чтобы преобразовать текст нам необходимо:\n",
    "1. Найти *N* самых популярных слов в *train* корпусе и пронумеровать их. У нас уже есть словарь с самыми популярными словами.\n",
    "2. Для каждого слова в корпусе создать нулевой вектор размерностью равной *N*.\n",
    "3. Для каждого текста в корпусе перебрать слова, находящиеся в словаре и увеличивать их значение на 1.\n",
    "\n",
    "Например, у нас есть список самых популярных слов:\n",
    "\n",
    "    ['hi', 'you', 'me', 'are']\n",
    "\n",
    "Мы их нумеруем и создаём словарь:\n",
    "\n",
    "    {'hi': 0, 'you': 1, 'me': 2, 'are': 3}\n",
    "\n",
    "И у нас есть текст, который надо трансформировать\n",
    "\n",
    "    'hi how are you'\n",
    "\n",
    "Для текста мы создаём нулевой вектор\n",
    "\n",
    "    [0, 0, 0, 0]\n",
    "    \n",
    "И итерируемся по всем словам, если слово есть в словаре, мы увеличиваем число в векторе:\n",
    "\n",
    "    'hi':  [1, 0, 0, 0] # hi — в нашем словаре имеет номер 0, значит встаёт на нулевую позицию\n",
    "    'how': [1, 0, 0, 0] # слово 'how' отсутствует в словаре, поэтому на второй итерации ничего не происходит\n",
    "    'are': [1, 0, 0, 1] # are в словаре на 3-й позиции, поэтому у нас появляется единичка на третей позиции\n",
    "    'you': [1, 1, 0, 1]\n",
    "\n",
    "Важно помнить, что этот вектор создаётся на основе словаря и он будет иметь его длину (а не длину предложения, здесь длины совпали)\n",
    "\n",
    "Итоговый вектор:\n",
    "\n",
    "    [1, 1, 0, 1]\n",
    "   \n",
    "Реализуем описанный метод в функции *my_bag_of_words* с размеров словаря равным 5000. Для поиска самых популярных слов исопльзуем *train* датасет. После проверим нашу функцию в *test_my_bag_of_words*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "DICT_SIZE = 5000\n",
    "\n",
    "# Повторяем поиск популярных слов, но ограничиваем размер до 5000\n",
    "most_common_words = sorted(words_counts.items(), key=lambda x: x[1], reverse=True)[:DICT_SIZE]\n",
    "\n",
    "# Создадим словарь типа {0: 'using', 1: 'php', 2: 'java', 3: 'file', 4: 'javascript'...}\n",
    "INDEX_TO_WORDS = dict(enumerate([i[0] for i in  most_common_words]))\n",
    "\n",
    "# Создадим такой же словарь, но поменяем местами номера и слова (теперь сначала слова, потом их номера)\n",
    "# Словарь типа {'using': 0, 'php': 1, 'java': 2, 'file': 3, 'javascript': 4...}\n",
    "WORDS_TO_INDEX = {v:k for k, v in INDEX_TO_WORDS.items()}\n",
    "\n",
    "# Создадим лист, куда поместимс все наши слова (без нумерации)\n",
    "ALL_WORDS = WORDS_TO_INDEX.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('using', 8278),\n",
       " ('php', 5614),\n",
       " ('java', 5501),\n",
       " ('file', 5055),\n",
       " ('javascript', 4746)]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "most_common_words[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_bag_of_words(text, words_to_index, dict_size):\n",
    "    \"\"\"\n",
    "        text: a string\n",
    "        dict_size: size of the dictionary\n",
    "        \n",
    "        return a vector which is a bag-of-words representation of 'text'\n",
    "    \"\"\"\n",
    "    # Создаём нулевой вектор размером словаря\n",
    "    result_vector = np.zeros(dict_size)\n",
    "\n",
    "    # Для каждого слова в тексте\n",
    "    for w in nltk.word_tokenize(text):\n",
    "        # Для каждого слова и индекса в словаре WORDS_TO_INDEX (подаётся вторым)\n",
    "        for word, i in words_to_index.items():\n",
    "            # Проверяем, есть ли слово в нашем словаре и если есть на место этого слова в векторе добавляем единичку\n",
    "            if word == w:                     \n",
    "                result_vector[i] += 1 \n",
    "    \n",
    "    return result_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_my_bag_of_words():\n",
    "    words_to_index = {'hi': 0, 'you': 1, 'me': 2, 'are': 3}\n",
    "    examples = ['hi how are you']\n",
    "    answers = [[1, 1, 0, 1]]\n",
    "    for ex, ans in zip(examples, answers):\n",
    "        if (my_bag_of_words(ex, words_to_index, 4) != ans).any():\n",
    "            return \"Wrong answer for the case: '%s'\" % ex\n",
    "    return 'Basic tests are passed.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Basic tests are passed.\n"
     ]
    }
   ],
   "source": [
    "print(test_my_bag_of_words())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь применим нашу функцию ко всем данным (это может занять несколько минут)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import sparse as sp_sparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape  (100000, 5000)\n",
      "X_val shape  (30000, 5000)\n",
      "X_test shape  (20000, 5000)\n"
     ]
    }
   ],
   "source": [
    "# Для каждого объекта в данных с признаками применим функцию преобразования в вектор, потом сохраним этот вектор в сжатом виде\n",
    "# А после чего соберём эти векторы в одну матрицу (добавлением строки вниз)\n",
    "\n",
    "X_train_mybag = sp_sparse.vstack([sp_sparse.csr_matrix(my_bag_of_words(text, WORDS_TO_INDEX, DICT_SIZE)) for text in X_train])\n",
    "X_val_mybag = sp_sparse.vstack([sp_sparse.csr_matrix(my_bag_of_words(text, WORDS_TO_INDEX, DICT_SIZE)) for text in X_val])\n",
    "X_test_mybag = sp_sparse.vstack([sp_sparse.csr_matrix(my_bag_of_words(text, WORDS_TO_INDEX, DICT_SIZE)) for text in X_test])\n",
    "print('X_train shape ', X_train_mybag.shape)\n",
    "print('X_val shape ', X_val_mybag.shape)\n",
    "print('X_test shape ', X_test_mybag.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Существует много представлений матриц в сжатом виде, однако sklearn умеет работать именно с таким типом, поэтому мы используем csr_matrix. Результат:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Как выглядела строка: ipad selecting text inside text input tap\n",
      "Как она выглядит сейчас: [0. 0. 0. ... 0. 0. 0.]\n",
      "Количество ненулевых элементов в векторе строки: 7\n"
     ]
    }
   ],
   "source": [
    "print('Как выглядела строка:', X_train[11])\n",
    "print('Как она выглядит сейчас:', X_train_mybag[11].toarray()[0])\n",
    "print('Количество ненулевых элементов в векторе строки:', np.count_nonzero(X_train_mybag[10].toarray()[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7 — потому что в строке дважды слово *text*, следовательно, на одной позиции вектор имеет число 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TF-IDF\n",
    "\n",
    "Второй метод несколько расширяет возможности мешка слов и использует суммарные частоты появления слов в документах. Также этот подход наказывает за слишком частые слова.\n",
    "\n",
    "Реализуем функцию *tfidf_features* с помощью класса [TfidfVectorizer](http://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html) из *scikit-learn*. Потом мы используем *train* корпус чтобы обучить векторайзер. Важно настроить аргументы, которые мы собираемся ему передать. Мы предполагаем отфильтровать слишком редкие слова (которые появляются менее, чем в 5 документах) и слишком частые слова (появляются в более чем 90% документах). Также используем биграмы наряду с униграмами."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tfidf_features(X_train, X_val, X_test):\n",
    "    \"\"\"\n",
    "        X_train, X_val, X_test — samples        \n",
    "        return TF-IDF vectorized representation of each sample and vocabulary\n",
    "    \"\"\"\n",
    "    # Создаём TF-IDF векторайзер с аргуемнтами, которые мы выбрали\n",
    "    tfidf_vectorizer = TfidfVectorizer(min_df=5, max_df=0.9, ngram_range=(1,2))\n",
    "\n",
    "    # Обучаем векторайзер на train данных и трансформируем их\n",
    "    X_train = tfidf_vectorizer.fit_transform(X_train)\n",
    "    \n",
    "    # Трансформируем по обученному векторайзеру наборы val и test и возвращаем всё\n",
    "    X_val = tfidf_vectorizer.transform(X_val)\n",
    "    X_test = tfidf_vectorizer.transform(X_test)\n",
    "    \n",
    "    return X_train, X_val, X_test, tfidf_vectorizer.vocabulary_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "После предварительной обработки важно посмотреть на результаты. С этим нужно быть очень осторожныи, так как именно от этого зависит качество модели. \n",
    "\n",
    "В этом случае проверим, находятся ли c++ или c# в нашем наборе, так как очевидно, они являются важными маркерами."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_tfidf, X_val_tfidf, X_test_tfidf, tfidf_vocab = tfidf_features(X_train, X_val, X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Создадим обратный словарь, где ключом будет частота слов, а значением - сами слова\n",
    "tfidf_reversed_vocab = {i:word for word, i in tfidf_vocab.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train_tfidf (100000, 17778)\n",
      "X_test_tfidf (20000, 17778)\n",
      "X_val_tfidf (30000, 17778)\n"
     ]
    }
   ],
   "source": [
    "print('X_train_tfidf', X_train_tfidf.shape) \n",
    "print('X_test_tfidf', X_test_tfidf.shape) \n",
    "print('X_val_tfidf', X_val_tfidf.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'c++' in tfidf_reversed_vocab.values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'c#' in tfidf_reversed_vocab.values()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как видим, теги *c++* и *c#* не находятся в нашем словаре. Что же произошло? Здесь следует вернуться к токенизации с помощью TfidfVectorizer. К счастью, мы можем повлиять на это. Давайте повторим токенизацию с помощью паттерна regexp *(\\S+)*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tfidf_features(X_train, X_val, X_test):\n",
    "    \"\"\"\n",
    "        X_train, X_val, X_test — samples        \n",
    "        return TF-IDF vectorized representation of each sample and vocabulary\n",
    "    \"\"\"\n",
    "    # Создаём TF-IDF векторайзер с аргуемнтами, которые мы выбрали\n",
    "    tfidf_vectorizer = TfidfVectorizer(min_df=5, max_df=0.9, ngram_range=(1,2), token_pattern='(\\S+)')\n",
    "\n",
    "    # Обучаем векторайзер на train данных и трансформируем их\n",
    "    X_train = tfidf_vectorizer.fit_transform(X_train)\n",
    "    \n",
    "    # Трансформируем по обученному векторайзеру наборы val и test и возвращаем всё\n",
    "    X_val = tfidf_vectorizer.transform(X_val)\n",
    "    X_test = tfidf_vectorizer.transform(X_test)\n",
    "    \n",
    "    return X_train, X_val, X_test, tfidf_vectorizer.vocabulary_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train_tfidf (100000, 18300)\n",
      "X_test_tfidf (20000, 18300)\n",
      "X_val_tfidf (30000, 18300)\n"
     ]
    }
   ],
   "source": [
    "X_train_tfidf, X_val_tfidf, X_test_tfidf, tfidf_vocab = tfidf_features(X_train, X_val, X_test)\n",
    "tfidf_reversed_vocab = {i:word for word, i in tfidf_vocab.items()}\n",
    "\n",
    "print('X_train_tfidf', X_train_tfidf.shape) \n",
    "print('X_test_tfidf', X_test_tfidf.shape) \n",
    "print('X_val_tfidf', X_val_tfidf.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'c++' in tfidf_reversed_vocab.values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'c#' in tfidf_reversed_vocab.values()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Многоклассовая классификация\n",
    "\n",
    "Как мы уже заметили, в этой задаче ответ может принимать несколько меток (тегов). Чтобы работать с такими предсказаниями, нам нужно закодировать все предсказания как 0 и 1 для тегов. Для этого существует [MultiLabelBinarizer](http://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.MultiLabelBinarizer.html) из библиотеки *sklearn*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MultiLabelBinarizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'r': 1727,\n",
       " 'php': 13907,\n",
       " 'mysql': 3092,\n",
       " 'c#': 19077,\n",
       " 'javascript': 19078,\n",
       " 'jquery': 7510,\n",
       " 'java': 18661,\n",
       " 'ruby-on-rails': 3344,\n",
       " 'ruby': 2326,\n",
       " 'ruby-on-rails-3': 692,\n",
       " 'json': 2026,\n",
       " 'spring': 1346,\n",
       " 'spring-mvc': 618,\n",
       " 'codeigniter': 786,\n",
       " 'class': 509,\n",
       " 'html': 4668,\n",
       " 'ios': 3256,\n",
       " 'c++': 6469,\n",
       " 'eclipse': 992,\n",
       " 'python': 8940,\n",
       " 'list': 693,\n",
       " 'objective-c': 4338,\n",
       " 'swift': 1465,\n",
       " 'xaml': 438,\n",
       " 'asp.net': 3939,\n",
       " 'wpf': 1289,\n",
       " 'multithreading': 1118,\n",
       " 'image': 672,\n",
       " 'performance': 512,\n",
       " 'twitter-bootstrap': 501,\n",
       " 'linq': 964,\n",
       " 'xml': 1347,\n",
       " 'numpy': 502,\n",
       " 'ajax': 1767,\n",
       " 'django': 1835,\n",
       " 'laravel': 525,\n",
       " 'android': 2818,\n",
       " 'rest': 456,\n",
       " 'asp.net-mvc': 1244,\n",
       " 'web-services': 633,\n",
       " 'string': 1573,\n",
       " 'excel': 443,\n",
       " 'winforms': 1468,\n",
       " 'arrays': 2277,\n",
       " 'c': 3119,\n",
       " 'sockets': 579,\n",
       " 'osx': 490,\n",
       " 'entity-framework': 649,\n",
       " 'mongodb': 350,\n",
       " 'opencv': 401,\n",
       " 'xcode': 900,\n",
       " 'uitableview': 460,\n",
       " 'algorithm': 419,\n",
       " 'python-2.7': 421,\n",
       " 'angularjs': 1353,\n",
       " 'dom': 400,\n",
       " 'swing': 759,\n",
       " '.net': 3872,\n",
       " 'vb.net': 1918,\n",
       " 'google-maps': 408,\n",
       " 'hibernate': 807,\n",
       " 'wordpress': 478,\n",
       " 'iphone': 1909,\n",
       " 'sql': 1272,\n",
       " 'visual-studio': 574,\n",
       " 'linux': 793,\n",
       " 'facebook': 508,\n",
       " 'database': 740,\n",
       " 'file': 582,\n",
       " 'generics': 420,\n",
       " 'visual-studio-2010': 588,\n",
       " 'regex': 1442,\n",
       " 'html5': 842,\n",
       " 'jsp': 680,\n",
       " 'csv': 435,\n",
       " 'forms': 872,\n",
       " 'validation': 558,\n",
       " 'parsing': 403,\n",
       " 'function': 487,\n",
       " 'pandas': 479,\n",
       " 'sorting': 375,\n",
       " 'qt': 451,\n",
       " 'wcf': 389,\n",
       " 'css': 1769,\n",
       " 'date': 560,\n",
       " 'node.js': 771,\n",
       " 'sql-server': 585,\n",
       " 'unit-testing': 449,\n",
       " 'python-3.x': 379,\n",
       " 'loops': 389,\n",
       " 'windows': 838,\n",
       " 'pointers': 350,\n",
       " 'oop': 425,\n",
       " 'datetime': 557,\n",
       " 'servlets': 498,\n",
       " 'session': 415,\n",
       " 'cocoa-touch': 507,\n",
       " 'apache': 441,\n",
       " 'selenium': 431,\n",
       " 'maven': 432}"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tags_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlb = MultiLabelBinarizer(classes=sorted(tags_counts.keys())) # Создаём объект кодировщика с классами из tags_count (отклики)\n",
    "y_train = mlb.fit_transform(y_train) # Применяем его к train и val, на test мы не обучаемся\n",
    "y_val = mlb.fit_transform(y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь реализуем функцию *train_classifier* для обучения классификатора. В этой задаче мы предполагаем использовать One-vs-Rest подход, который включён в класс [OneVsRestClassifier](http://scikit-learn.org/stable/modules/generated/sklearn.multiclass.OneVsRestClassifier.html). При таком подходе обучается столько классификаторов, сколько у нас тегов (k). За базовый классификатор возьмём [LogisticRegression](http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html). Это довольно простой метод, однако он достаточно хорошо справляется с задачами классификации текста."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.linear_model import LogisticRegression, RidgeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_classifier(X_train, y_train):\n",
    "    \"\"\"\n",
    "      X_train, y_train — training data\n",
    "      \n",
    "      return: trained classifier\n",
    "    \"\"\"\n",
    "    \n",
    "    model = OneVsRestClassifier(LogisticRegression()).fit(X_train, y_train)\n",
    "\n",
    "    return model  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обучим классификатор для разных наборов — Bag of Words и TF-IDF."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BOW done.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TFIDF done.\n"
     ]
    }
   ],
   "source": [
    "classifier_mybag = train_classifier(X_train_mybag, y_train)\n",
    "print('BOW done.')\n",
    "classifier_tfidf = train_classifier(X_train_tfidf, y_train)\n",
    "print('TFIDF done.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь мы можем прогнозировать данные. Мы будем использовать два типа прогноза - метки и decision function, последнее даёт нам сырые предсказания чисел типа -0.348 или 0.225, метки основываются на этих предсказаниях и выдают 1, если число положительное и 0 в противном случае (если граница на 0)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_val_predicted_labels_mybag = classifier_mybag.predict(X_val_mybag)\n",
    "y_val_predicted_scores_mybag = classifier_mybag.decision_function(X_val_mybag)\n",
    "\n",
    "y_val_predicted_labels_tfidf = classifier_tfidf.predict(X_val_tfidf)\n",
    "y_val_predicted_scores_tfidf = classifier_tfidf.decision_function(X_val_tfidf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрим на предсказания"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(),\n",
       " (),\n",
       " ('json', 'ruby-on-rails'),\n",
       " (),\n",
       " ('ruby-on-rails',),\n",
       " (),\n",
       " (),\n",
       " ('python',),\n",
       " ('javascript', 'jquery'),\n",
       " ('hibernate', 'java')]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Предсказания TF-IDF\n",
    "y_val_pred_inversed = mlb.inverse_transform(y_val_predicted_labels_tfidf) # Обратная трансформация (мы же закодировали метки)\n",
    "y_val_pred_inversed[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(),\n",
       " (),\n",
       " ('ruby-on-rails',),\n",
       " ('ruby',),\n",
       " ('json', 'ruby-on-rails'),\n",
       " (),\n",
       " (),\n",
       " ('python',),\n",
       " ('javascript', 'jquery'),\n",
       " ('hibernate', 'java')]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Сначала наши предсказания BoW\n",
    "y_val_pred_inversed = mlb.inverse_transform(y_val_predicted_labels_mybag)\n",
    "y_val_pred_inversed[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('php', 'sql'),\n",
       " ('javascript',),\n",
       " ('ruby', 'ruby-on-rails'),\n",
       " ('ruby', 'session'),\n",
       " ('json', 'ruby', 'ruby-on-rails'),\n",
       " ('c++', 'ios', 'iphone', 'xcode'),\n",
       " ('c#',),\n",
       " ('django', 'python'),\n",
       " ('html', 'javascript', 'jquery'),\n",
       " ('hibernate', 'java')]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Реальные метки\n",
    "y_val_inversed = mlb.inverse_transform(y_val)\n",
    "y_val_inversed[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь сравним результатыт и посмотрим, помогает ли TF-IDF или стоит попоробовать регуляризацию в логистической регрессии. Для всех этих экспериментов нам необходимо установить метрики."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Метрики\n",
    "\n",
    "Используем несколько метрик:\n",
    " - [Accuracy](http://scikit-learn.org/stable/modules/generated/sklearn.metrics.accuracy_score.html)\n",
    " - [F1-score](http://scikit-learn.org/stable/modules/generated/sklearn.metrics.f1_score.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import average_precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import make_scorer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Реализуем функцию *print_evaluation_scores*, которая вычисляет и выдаёт:\n",
    " - *accuracy*\n",
    " - *F1-score macro/micro/weighted*\n",
    " - *Precision macro/micro/weighted*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_evaluation_scores(y_val, predicted):\n",
    "    \n",
    "    accuracy = accuracy_score(y_val, predicted)\n",
    "    f1 = f1_score(y_val, predicted, average='weighted')\n",
    "    precision = average_precision_score(y_val, predicted, average='weighted')\n",
    "    recall = recall_score(y_val, predicted, average='weighted')\n",
    "    print('Accuracy:', round(accuracy, 3))\n",
    "    print('F1 score:', round(f1, 3))\n",
    "    print('Precision:', round(precision, 3))\n",
    "    print('Recall:', round(recall, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bag of words\n",
      "Accuracy: 0.349\n",
      "F1 score: 0.65\n",
      "Precision: 0.5\n",
      "Recall: 0.573\n",
      "\n",
      "TF-IDF\n",
      "Accuracy: 0.334\n",
      "F1 score: 0.614\n",
      "Precision: 0.485\n",
      "Recall: 0.501\n"
     ]
    }
   ],
   "source": [
    "print('Bag of words')\n",
    "print_evaluation_scores(y_val, y_val_predicted_labels_mybag)\n",
    "print()\n",
    "print('TF-IDF')\n",
    "print_evaluation_scores(y_val, y_val_predicted_labels_tfidf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как видим, BoW в целом справился лучше с классификацией (хотя обе модели далеки от идеала)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MultilabelClassification\n",
    "После выбора метрики, можно поэкспериментировать с классифиактором. Будем использовать взвешенную F1-меру."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.351\n",
      "F1 score: 0.639\n",
      "Precision: 0.497\n",
      "Recall: 0.543\n"
     ]
    }
   ],
   "source": [
    "# Сначала попробуем поменять параметры в TF-IDF\n",
    "def tfidf_features(X_train, X_val, X_test):\n",
    "    tfidf_vectorizer = TfidfVectorizer(min_df=30, max_df=0.8, ngram_range=(1,2), token_pattern='(\\S+)')\n",
    "    X_train = tfidf_vectorizer.fit_transform(X_train)\n",
    "    X_val = tfidf_vectorizer.transform(X_val)\n",
    "    X_test = tfidf_vectorizer.transform(X_test)\n",
    "    \n",
    "    return X_train, X_val, X_test, tfidf_vectorizer.vocabulary_\n",
    "\n",
    "X_train_tfidf, X_val_tfidf, X_test_tfidf, tfidf_vocab = tfidf_features(X_train, X_val, X_test)\n",
    "tfidf_reversed_vocab = {i:word for word, i in tfidf_vocab.items()}\n",
    "\n",
    "print('X_train_tfidf', X_train_tfidf.shape) \n",
    "print('X_test_tfidf', X_test_tfidf.shape) \n",
    "print('X_val_tfidf', X_val_tfidf.shape)\n",
    "\n",
    "classifier_tfidf = train_classifier(X_train_tfidf, y_train)\n",
    "\n",
    "y_val_predicted_labels_tfidf = classifier_tfidf.predict(X_val_tfidf)\n",
    "y_val_predicted_scores_tfidf = classifier_tfidf.decision_function(X_val_tfidf)\n",
    "\n",
    "# Предсказания TF-IDF\n",
    "y_val_pred_inversed = mlb.inverse_transform(y_val_predicted_labels_tfidf) # Обратная трансформация (мы же закодировали метки)\n",
    "y_val_pred_inversed[:10]\n",
    "\n",
    "print_evaluation_scores(y_val, y_val_predicted_labels_tfidf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Результаты стали лучше, но это не сильно помогло"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
